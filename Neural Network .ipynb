{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy.special\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural Network Class Definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # number of input, hidden and output nodes.\n",
    "        self.iNodes = input_nodes\n",
    "        self.hNodes = hidden_nodes\n",
    "        self.oNodes = output_nodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is\n",
    "        # from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc\n",
    "        self.wih = numpy.random.normal(0.0, pow(self.hNodes, -0.5), (self.hNodes, self.iNodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.oNodes, -0.5), (self.oNodes, self.hNodes))\n",
    "        \n",
    "        # learning rate\n",
    "        self.learningRate = learning_rate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "    # train the neural network\n",
    "    # two phases to training, the first\n",
    "    # is calculating the output just as query() does it, and \n",
    "    # the second part is backpropagating the errors to inform how the \n",
    "    # link weights are refined\n",
    "    def train(self, input_list, target_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(input_list, ndmin=2).T\n",
    "        targets = numpy.array(target_list, ndmin=2).T\n",
    "        \n",
    "        # Calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        \n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # Calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_inputs)\n",
    "        \n",
    "        # Calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (Target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        \n",
    "        # hidden layer error is the output_errors, split by weights\n",
    "        # recombinded at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.learningRate * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), \\\n",
    "                                       numpy.transpose(hidden_inputs))\n",
    "        \n",
    "        # update the wieghts for links between the input and hidden layers\n",
    "        self.wih += self.learningRate * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), \\\n",
    "                                       numpy.transpose(inputs))\n",
    "        \n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, input_list):\n",
    "        # convert inputs list to 2d array\n",
    "        # .T tranposes the matrix\n",
    "        inputs = numpy.array(input_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layers\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        \n",
    "        # calculate signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        \n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create instance of neural network\n",
    "n = neuralNetwork(3, 3, 3, .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.58684762]\n",
      " [ 0.48420681]\n",
      " [ 0.45099378]]\n"
     ]
    }
   ],
   "source": [
    "# link weight matrices practice\n",
    "print n.query([1.0, 0.5, -1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_file = open(\"Desktop/mnist_dataset/mnist_train_100.csv\", 'r')\n",
    "training_data_list = data_file.readlines()\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,18,18,18,126,136,175,26,166,255,247,127,0,0,0,0,0,0,0,0,0,0,0,0,30,36,94,154,170,253,253,253,253,253,225,172,253,242,195,64,0,0,0,0,0,0,0,0,0,0,0,49,238,253,253,253,253,253,253,253,253,251,93,82,82,56,39,0,0,0,0,0,0,0,0,0,0,0,0,18,219,253,253,253,253,253,198,182,247,241,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,80,156,107,253,253,205,11,0,43,154,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,154,253,90,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,139,253,190,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,190,253,70,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,35,241,225,160,108,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,81,240,253,253,119,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,45,186,253,253,150,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,93,252,253,187,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,249,253,249,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,46,130,183,253,253,207,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,39,148,229,253,253,253,250,182,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,114,221,253,253,253,253,201,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,66,213,253,253,253,253,198,81,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,171,219,253,253,253,253,195,80,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,172,226,253,253,253,253,244,133,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,136,253,253,253,212,135,132,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '3', '18', '18', '18', '126', '136', '175', '26', '166', '255', '247', '127', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '30', '36', '94', '154', '170', '253', '253', '253', '253', '253', '225', '172', '253', '242', '195', '64', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '49', '238', '253', '253', '253', '253', '253', '253', '253', '253', '251', '93', '82', '82', '56', '39', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '18', '219', '253', '253', '253', '253', '253', '198', '182', '247', '241', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '80', '156', '107', '253', '253', '205', '11', '0', '43', '154', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '14', '1', '154', '253', '90', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '139', '253', '190', '2', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '11', '190', '253', '70', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '35', '241', '225', '160', '108', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '81', '240', '253', '253', '119', '25', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '45', '186', '253', '253', '150', '27', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '16', '93', '252', '253', '187', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '249', '253', '249', '64', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '46', '130', '183', '253', '253', '207', '2', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '39', '148', '229', '253', '253', '253', '250', '182', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '24', '114', '221', '253', '253', '253', '253', '201', '78', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '23', '66', '213', '253', '253', '253', '253', '198', '81', '2', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '18', '171', '219', '253', '253', '253', '253', '195', '80', '9', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '55', '172', '226', '253', '253', '253', '253', '244', '133', '11', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '136', '253', '253', '253', '212', '135', '132', '16', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0\\n']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x105eedb90>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105c77490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# lets split the long string by its commas\n",
    "all_values = training_data_list[0].split(',')\n",
    "print(all_values)\n",
    "\n",
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.02164706\n",
      "  0.07988235  0.07988235  0.07988235  0.49917647  0.538       0.68941176\n",
      "  0.11094118  0.65447059  1.          0.96894118  0.50305882  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.12647059  0.14976471  0.37494118\n",
      "  0.60788235  0.67        0.99223529  0.99223529  0.99223529  0.99223529\n",
      "  0.99223529  0.88352941  0.67776471  0.99223529  0.94952941  0.76705882\n",
      "  0.25847059  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.20023529\n",
      "  0.934       0.99223529  0.99223529  0.99223529  0.99223529  0.99223529\n",
      "  0.99223529  0.99223529  0.99223529  0.98447059  0.37105882  0.32835294\n",
      "  0.32835294  0.22741176  0.16141176  0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.07988235  0.86023529  0.99223529  0.99223529  0.99223529\n",
      "  0.99223529  0.99223529  0.77870588  0.71658824  0.96894118  0.94564706\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.32058824  0.61564706\n",
      "  0.42541176  0.99223529  0.99223529  0.80588235  0.05270588  0.01\n",
      "  0.17694118  0.60788235  0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.06435294  0.01388235  0.60788235  0.99223529  0.35941176  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.54964706  0.99223529  0.74764706  0.01776471\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.05270588  0.74764706  0.99223529\n",
      "  0.28176471  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.14588235\n",
      "  0.94564706  0.88352941  0.63117647  0.42929412  0.01388235  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.32447059  0.94176471  0.99223529  0.99223529  0.472       0.10705882\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.18470588  0.73211765  0.99223529  0.99223529\n",
      "  0.59235294  0.11482353  0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.07211765  0.37105882\n",
      "  0.98835294  0.99223529  0.736       0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.97670588  0.99223529  0.97670588  0.25847059  0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.18858824  0.51470588\n",
      "  0.72047059  0.99223529  0.99223529  0.81364706  0.01776471  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.16141176  0.58458824  0.89905882\n",
      "  0.99223529  0.99223529  0.99223529  0.98058824  0.71658824  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.10317647  0.45258824  0.868       0.99223529\n",
      "  0.99223529  0.99223529  0.99223529  0.79035294  0.31282353  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.09929412  0.26623529  0.83694118  0.99223529  0.99223529\n",
      "  0.99223529  0.99223529  0.77870588  0.32447059  0.01776471  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.07988235  0.67388235  0.86023529  0.99223529  0.99223529  0.99223529\n",
      "  0.99223529  0.76705882  0.32058824  0.04494118  0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.22352941  0.67776471  0.88741176  0.99223529  0.99223529  0.99223529\n",
      "  0.99223529  0.95729412  0.52635294  0.05270588  0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.538       0.99223529  0.99223529  0.99223529  0.83305882\n",
      "  0.53411765  0.52247059  0.07211765  0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01      ]\n"
     ]
    }
   ],
   "source": [
    "# We need to scale out input to our neural network\n",
    "# scale input to range .01 to 1.00\n",
    "scaled_input = (numpy.asfarray(all_values[1:]) / 255.0 * .99) + .01\n",
    "print(scaled_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "\n",
    "learning_rate = .3\n",
    "\n",
    "# create instance of neural network\n",
    "\n",
    "my_net = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "# train the neural network\n",
    "# go through all records in the training data set\n",
    "for record in training_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * .99) + .01\n",
    "    # create the target output values (all .01, except the desired label which is .99)\n",
    "    targets = numpy.zeros(output_nodes) + .01\n",
    "    # all_values[0] is the target label for this record\n",
    "    targets[int(all_values[0])] = .99\n",
    "    my_net.train(inputs, targets)\n",
    "    \n",
    "# output nodes is 10\n",
    "oNodes = 10\n",
    "targets = numpy.zeros(oNodes) + .01\n",
    "targets[int(all_values[0])] = .99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# Test The first example for fun\n",
    "\n",
    "# Load the mnist test data CSV file into a list\n",
    "test_data_file = open(\"Desktop/mnist_dataset/mnist_test_10.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()\n",
    "\n",
    "# Get the first test record\n",
    "all_values = test_data_list[0].split(',')\n",
    "# Print the label\n",
    "print(all_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x106b5e890>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIAQeCITAA4EQeCCQ/we9qso8Fdv/sAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105f35910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.77399876e-02],\n",
       "       [  2.34024582e-03],\n",
       "       [  2.87165897e-03],\n",
       "       [  1.67797221e-03],\n",
       "       [  2.55762518e-02],\n",
       "       [  3.03383904e-01],\n",
       "       [  3.46628313e-04],\n",
       "       [  9.74430696e-01],\n",
       "       [  3.74495543e-01],\n",
       "       [  1.57815437e-01]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_net.query((numpy.asfarray(all_values[1:]) / 255.0 * .99) + .01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Test The Entire Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 'correct label')\n",
      "(7, \"network's answer\")\n",
      "(2, 'correct label')\n",
      "(0, \"network's answer\")\n",
      "(1, 'correct label')\n",
      "(1, \"network's answer\")\n",
      "(0, 'correct label')\n",
      "(0, \"network's answer\")\n",
      "(4, 'correct label')\n",
      "(4, \"network's answer\")\n",
      "(1, 'correct label')\n",
      "(1, \"network's answer\")\n",
      "(4, 'correct label')\n",
      "(9, \"network's answer\")\n",
      "(9, 'correct label')\n",
      "(3, \"network's answer\")\n",
      "(5, 'correct label')\n",
      "(5, \"network's answer\")\n",
      "(9, 'correct label')\n",
      "(7, \"network's answer\")\n"
     ]
    }
   ],
   "source": [
    "# scorecard for how well the netowrk performs, intially empty scorecard = []\n",
    "scorecard = []\n",
    "# go through all the records in the test data set \n",
    "for record in test_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer in first value\n",
    "    correct_label = int(all_values[0])\n",
    "    print(correct_label, \"correct label\")\n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * .99) + .01\n",
    "    # query the network\n",
    "    outputs = my_net.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "    print(label, \"network's answer\")\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # netowrk's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 1, 1, 1, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(scorecard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the performance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance = 60.0%\n"
     ]
    }
   ],
   "source": [
    "scorecard_array = numpy.asarray(scorecard)\n",
    "scoreSum = float(scorecard_array.sum())\n",
    "scoreLen = float(scorecard_array.size)\n",
    "finalScore = str((scoreSum/scoreLen) * 100)\n",
    "print \"Performance = \" + finalScore + \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Train on Full MNIST Data-Set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
